import tensorflow as tf
import numpy as np
import cv2
import os
import json
import tkinter as tk
from tkinter import filedialog
from PIL import Image, ImageGrab
import time

# --- 1. é…ç½®èˆ‡åƒæ•¸è¨­å®š ---
MODEL_SAVE_PATH = "trained_model_tf"
CHECKPOINT_FILE = "latest_checkpoint_cifar10_mobilenet.keras"
CLASS_INDICES_FILE = "class_indices_cifar10.json"
CHECKPOINT_PATH = os.path.join(MODEL_SAVE_PATH, CHECKPOINT_FILE)

# è¨­å®šä¿¡å¿ƒåº¦/æ©Ÿç‡é–¥å€¼ (ä¾‹å¦‚ 0.4ï¼Œä½æ–¼æ­¤å€¼é¡¯ç¤º Unknown. é¡åˆ¥æ•¸è¶Šå¤šé€™å€‹è¦è¶Šä½.
# åœ¨ "before softmax" å¯¦æ–½æª¢æŸ¥çš„ç¼ºé»ï¼šLogits çš„æ•¸å€¼ç¯„åœä¸å›ºå®šï¼Œå¯èƒ½æ˜¯ 5.0ï¼Œä¹Ÿå¯èƒ½æ˜¯ 50.0ï¼Œé€™å–æ±ºæ–¼æ¨¡å‹çš„è¨“ç·´ç‹€æ…‹ï¼Œå› æ­¤é–€æª»æ¥µé›£è¨­å®š.
# CONFIDENCE_THRESHOLD = 0.4  # æ•ˆæœé‚„æ˜¯ä¸å¥½.

# æ”¹æˆè¨­å®šæ©Ÿç‡é–“éš™é–€æª» (ç¬¬ä¸€åæ©Ÿç‡ - ç¬¬äºŒåæ©Ÿç‡)
# ä¾‹å¦‚ 0.05 ä»£è¡¨ç¬¬ä¸€åå¿…é ˆé ˜å…ˆç¬¬äºŒå 5% ä»¥ä¸Šæ‰ç®—å‹å‡º
MARGIN_THRESHOLD = 0.05

IMAGE_SIZE = (224, 224)
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
IMAGENET_STD = np.array([0.229, 0.224, 0.225])

# æŒ‰éˆ•å€åŸŸå®šç¾© (x, y, w, h)
OPEN_BTN_RECT = (20, 450, 120, 40)

# --- 2. è¼”åŠ©åŠŸèƒ½ï¼šæª”æ¡ˆç€è¦½å™¨ ---
def select_image_file():
    root = tk.Tk()
    root.withdraw() # éš±è—ä¸»è¦–çª—
    file_path = filedialog.askopenfilename(
        title="é¸æ“‡æ¸¬è©¦åœ–æª”",
        filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.webp")]
    )
    root.destroy()
    return file_path

# --- 3. é è™•ç†èˆ‡æ¨è«– ---
def preprocess_image(pil_img):
    # è½‰ç‚º RGB ä¸¦ Resize
    img = pil_img.convert('RGB')
    img = img.resize(IMAGE_SIZE)
    # è½‰ç‚º numpy ä¸¦æ­¸ä¸€åŒ–åˆ° [0, 1]
    img_array = np.array(img).astype(np.float32) / 255.0
    # ImageNet æ¨™æº–åŒ–
    img_array = (img_array - IMAGENET_MEAN) / IMAGENET_STD
    # å¢åŠ  Batch ç¶­åº¦ (1, 224, 224, 3)
    return np.expand_dims(img_array, axis=0)

def run_inference(model, pil_img, class_names):
    input_data = preprocess_image(pil_img)
    predictions = model.predict(input_data, verbose=0)[0]  # model.predict è¼¸å‡ºæ˜¯ (1, N) çš„ NumPy é™£åˆ—
    # å› ç‚ºè¨“ç·´æ™‚æœŸçš„modelå®šç¾©æœ€å¾Œä¸€å±¤æ˜¯ layers.Dense(NUM_CLASSES, activation='softmax'), ä»£è¡¨è¼¸å‡ºå·²ç¶“æ˜¯softmaxå¾Œçš„æ©Ÿç‡, è€Œélogits.
    # æ‰€ä»¥é€™é‚Šçš„predictions å·²ç¶“æ˜¯æ©Ÿç‡.

    '''
    # å–å¾—æ©Ÿç‡æœ€é«˜çš„ç´¢å¼•
    idx = np.argmax(predictions)
    prob = predictions[idx]

    # æª¢æŸ¥æ˜¯å¦é”åˆ°é–¥å€¼
    if prob < CONFIDENCE_THRESHOLD:
        return "Unknown", prob * 100
    else:
        return class_names[str(idx)], prob * 100
    '''

    # æ’åºå–å¾—å‰å…©å
    # np.argsort(predictions) : å°‡ predictions é™£åˆ—ä¸­çš„æ•¸å€¼é€²è¡Œç”±å°åˆ°å¤§çš„æ’åºï¼Œä½†å®ƒå›å‚³çš„ä¸æ˜¯æ•¸å€¼ï¼Œè€Œæ˜¯åŸå§‹çš„ç´¢å¼•ï¼ˆIndexï¼‰ã€‚
    # ex. å‡è¨­ predictions æ˜¯ [0.1, 0.7, 0.2]ï¼ˆåˆ†åˆ¥ä»£è¡¨é¡åˆ¥ 0, 1, 2ï¼‰ã€‚ np.argsort æœƒå›å‚³ï¼š[0, 2, 1]ã€‚
    # [-2:] (åˆ‡ç‰‡æ“ä½œï¼šå–æœ€å¾Œå…©å€‹)
    # [::-1] (åˆ‡ç‰‡æ“ä½œï¼šåè½‰é †åº)
    top_indices = np.argsort(predictions)[-2:][::-1] # å–å¾—æœ€é«˜çš„å…©å€‹ index [æœ€é«˜, æ¬¡é«˜]
    top1_idx = top_indices[0]
    top2_idx = top_indices[1]
    
    top1_prob = predictions[top1_idx]
    top2_prob = predictions[top2_idx]
    
    margin = top1_prob - top2_prob
    print(f"Top1({class_names[str(top1_idx)]}): {top1_prob:.2f}, Top2({class_names[str(top2_idx)]}): {top2_prob:.2f}, Margin: {margin:.2f}")

    # åˆ¤æ–·é‚è¼¯ï¼šå·®è·å¤§æ–¼é–€æª»æ‰è¼¸å‡ºé¡åˆ¥
    if margin < MARGIN_THRESHOLD:
        return "Unknown", top1_prob * 100
    else:
        return class_names[str(top1_idx)], top1_prob * 100

# --- 4. ç¹ªè£½ UI ---
def draw_ui(frame, predicted_class=None, confidence=None):
    # ç¹ªè£½æŒ‰éˆ•
    x, y, w, h = OPEN_BTN_RECT
    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), -1)
    cv2.putText(frame, "OPEN FILE", (x + 10, y + 28), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    
    # ç¹ªè£½çµæœ
    if predicted_class:
        text = f"Class: {predicted_class} ({confidence:.1f}%)"
        cv2.putText(frame, text, (20, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
    
    cv2.putText(frame, "Press 'Q' to Quit | Clipboard Monitored", (20, 420), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

# --- 5. ä¸»ç¨‹å¼ ---
def main():
    # A. è¼‰å…¥é¡åˆ¥å­—å…¸
    try:
        with open(os.path.join(MODEL_SAVE_PATH, CLASS_INDICES_FILE), 'r') as f:
            indices = json.load(f)
            # åè½‰å­—å…¸: { "0": "plane", "1": "car" ... }
            class_names = {str(v): k for k, v in indices.items()}
    except Exception as e:
        print(f"ç„¡æ³•è®€å–é¡åˆ¥ç´¢å¼•æª”: {e}")
        return

    # B. è¼‰å…¥æ¨¡å‹ (TensorFlow ä¸éœ€è¦é‡å»ºçµæ§‹)
    print("æ­£åœ¨è¼‰å…¥ Keras æ¨¡å‹...")
    model = tf.keras.models.load_model(CHECKPOINT_PATH)
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")

    win_name = 'CIFAR-10 TF Inference'
    cv2.namedWindow(win_name)
    
    # ç”¨æ–¼æ»‘é¼ äº‹ä»¶è™•ç†
    params = {'clicked_open': False}
    def on_mouse(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            bx, by, bw, bh = OPEN_BTN_RECT
            if bx <= x <= bx + bw and by <= y <= by + bh:
                param['clicked_open'] = True
    
    cv2.setMouseCallback('CIFAR-10 TF Inference', on_mouse, params)

    last_clipboard_img = None
    current_pil_img = None
    predicted_class, confidence = None, None

    print("ğŸš€ æ¨è«–å¼•æ“å•Ÿå‹•ã€‚é»æ“Šè¦–çª—æŒ‰éˆ•ã€æŒ‰ 'O' éµæˆ–è¤‡è£½åœ–ç‰‡åˆ°å‰ªè²¼ç°¿...")

    while True:
        ''' 
        (ä¸work #1)
        # æª¢æŸ¥è¦–çª—æ˜¯å¦è¢«æŒ‰ X é—œé–‰
        if cv2.getWindowProperty(win_name, cv2.WND_PROP_AUTOSIZE) < 0:
            break
        '''
        '''
        (ä¸work #2)
        # --- è¦–çª—é—œé–‰åµæ¸¬ï¼šé›™é‡æª¢æŸ¥æ³• ---
        try:
            # åœ¨è¨±å¤šç³»çµ±ä¸Šï¼Œä¸€æ—¦é»æ“Š Xï¼ŒgetWindowProperty æœƒä¸Ÿå‡ºç•°å¸¸æˆ–å›å‚³ -1
            visible = cv2.getWindowProperty(win_name, cv2.WND_PROP_VISIBLE)
            if visible < 1: 
                break
        except:
            break # æ•æ‰åˆ°ç•°å¸¸ä»£è¡¨è¦–çª—å·²éŠ·æ¯€
        '''

        # 1. æª¢æŸ¥æŒ‰éˆ•é»æ“Šæˆ–æŒ‰éµ
        key = cv2.waitKey(30) & 0xFF
        if key == ord('q'): break
        
        if params['clicked_open'] or key == ord('o'):
            file_path = select_image_file()
            if file_path:
                current_pil_img = Image.open(file_path)
                predicted_class, confidence = run_inference(model, current_pil_img, class_names)
            params['clicked_open'] = False

        # 2. æª¢æŸ¥å‰ªè²¼ç°¿
        try:
            cb_img = ImageGrab.grabclipboard()
            if isinstance(cb_img, Image.Image):
                # ç°¡å–®çš„æ¯”å°æ–¹å¼ï¼šåˆ¤æ–·æ˜¯å¦ç‚ºæ–°åœ–
                if last_clipboard_img is None or cb_img.size != last_clipboard_img.size:
                    print("ğŸ“‹ åµæ¸¬åˆ°å‰ªè²¼ç°¿æ–°åœ–ç‰‡ï¼")
                    current_pil_img = cb_img
                    last_clipboard_img = cb_img
                    predicted_class, confidence = run_inference(model, current_pil_img, class_names)
        except:
            pass

        # 3. é¡¯ç¤ºç•«é¢
        if current_pil_img:
            # å°‡ PIL è½‰å› OpenCV æ ¼å¼é€²è¡Œé¡¯ç¤º
            display_img = np.array(current_pil_img.convert('RGB'))
            display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)
            # å›ºå®šé¡¯ç¤ºå¤§å°
            display_img = cv2.resize(display_img, (600, 500))
        else:
            display_img = np.zeros((500, 600, 3), dtype=np.uint8)

        draw_ui(display_img, predicted_class, confidence)
        cv2.imshow(win_name, display_img)

    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()