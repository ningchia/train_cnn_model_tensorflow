import tensorflow as tf
import numpy as np
import cv2
import os
import json
import tkinter as tk
from tkinter import filedialog
from PIL import Image, ImageGrab
import time

# --- 1. é…ç½®èˆ‡åƒæ•¸è¨­å®š ---
MODEL_SAVE_PATH = "trained_model_tf"
CHECKPOINT_FILE = "latest_checkpoint_cifar10_mobilenet.keras"
CLASS_INDICES_FILE = "class_indices_cifar10.json"
CHECKPOINT_PATH = os.path.join(MODEL_SAVE_PATH, CHECKPOINT_FILE)

IMAGE_SIZE = (224, 224)
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406])
IMAGENET_STD = np.array([0.229, 0.224, 0.225])

# æŒ‰éˆ•å€åŸŸå®šç¾© (x, y, w, h)
OPEN_BTN_RECT = (20, 450, 120, 40)

# --- 2. è¼”åŠ©åŠŸèƒ½ï¼šæª”æ¡ˆç€è¦½å™¨ ---
def select_image_file():
    root = tk.Tk()
    root.withdraw() # éš±è—ä¸»è¦–çª—
    file_path = filedialog.askopenfilename(
        title="é¸æ“‡æ¸¬è©¦åœ–æª”",
        filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.webp")]
    )
    root.destroy()
    return file_path

# --- 3. é è™•ç†èˆ‡æ¨è«– ---
def preprocess_image(pil_img):
    # è½‰ç‚º RGB ä¸¦ Resize
    img = pil_img.convert('RGB')
    img = img.resize(IMAGE_SIZE)
    # è½‰ç‚º numpy ä¸¦æ­¸ä¸€åŒ–åˆ° [0, 1]
    img_array = np.array(img).astype(np.float32) / 255.0
    # ImageNet æ¨™æº–åŒ–
    img_array = (img_array - IMAGENET_MEAN) / IMAGENET_STD
    # å¢åŠ  Batch ç¶­åº¦ (1, 224, 224, 3)
    return np.expand_dims(img_array, axis=0)

def run_inference(model, pil_img, class_names):
    input_data = preprocess_image(pil_img)
    predictions = model.predict(input_data, verbose=0)  # è¼¸å‡ºæ˜¯ (1, N) çš„ NumPy é™£åˆ—
    # å› ç‚ºè¨“ç·´æ™‚æœŸçš„modelå®šç¾©æœ€å¾Œä¸€å±¤æ˜¯ layers.Dense(NUM_CLASSES, activation='softmax'), ä»£è¡¨è¼¸å‡ºå·²ç¶“æ˜¯softmaxå¾Œçš„æ©Ÿç‡, è€Œélogits.
    # æ‰€ä»¥é€™é‚Šçš„predictions å·²ç¶“æ˜¯æ©Ÿç‡.
    
    # å–å¾—æ©Ÿç‡æœ€é«˜çš„ç´¢å¼•
    idx = np.argmax(predictions[0])
    confidence = predictions[0][idx]
    return class_names[str(idx)], confidence * 100

# --- 4. ç¹ªè£½ UI ---
def draw_ui(frame, predicted_class=None, confidence=None):
    # ç¹ªè£½æŒ‰éˆ•
    x, y, w, h = OPEN_BTN_RECT
    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), -1)
    cv2.putText(frame, "OPEN FILE", (x + 10, y + 28), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    
    # ç¹ªè£½çµæœ
    if predicted_class:
        text = f"Class: {predicted_class} ({confidence:.1f}%)"
        cv2.putText(frame, text, (20, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
    
    cv2.putText(frame, "Press 'Q' to Quit | Clipboard Monitored", (20, 420), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

# --- 5. ä¸»ç¨‹å¼ ---
def main():
    # A. è¼‰å…¥é¡åˆ¥å­—å…¸
    try:
        with open(os.path.join(MODEL_SAVE_PATH, CLASS_INDICES_FILE), 'r') as f:
            indices = json.load(f)
            # åè½‰å­—å…¸: { "0": "plane", "1": "car" ... }
            class_names = {str(v): k for k, v in indices.items()}
    except Exception as e:
        print(f"ç„¡æ³•è®€å–é¡åˆ¥ç´¢å¼•æª”: {e}")
        return

    # B. è¼‰å…¥æ¨¡å‹ (TensorFlow ä¸éœ€è¦é‡å»ºçµæ§‹)
    print("æ­£åœ¨è¼‰å…¥ Keras æ¨¡å‹...")
    model = tf.keras.models.load_model(CHECKPOINT_PATH)
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")

    cv2.namedWindow('CIFAR-10 TF Inference')
    
    # ç”¨æ–¼æ»‘é¼ äº‹ä»¶è™•ç†
    params = {'clicked_open': False}
    def on_mouse(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            bx, by, bw, bh = OPEN_BTN_RECT
            if bx <= x <= bx + bw and by <= y <= by + bh:
                param['clicked_open'] = True
    
    cv2.setMouseCallback('CIFAR-10 TF Inference', on_mouse, params)

    last_clipboard_img = None
    current_pil_img = None
    predicted_class, confidence = None, None

    print("ğŸš€ æ¨è«–å¼•æ“å•Ÿå‹•ã€‚é»æ“Šè¦–çª—æŒ‰éˆ•ã€æŒ‰ 'O' éµæˆ–è¤‡è£½åœ–ç‰‡åˆ°å‰ªè²¼ç°¿...")

    while True:
        # 1. æª¢æŸ¥æŒ‰éˆ•é»æ“Šæˆ–æŒ‰éµ
        key = cv2.waitKey(30) & 0xFF
        if key == ord('q'): break
        
        if params['clicked_open'] or key == ord('o'):
            file_path = select_image_file()
            if file_path:
                current_pil_img = Image.open(file_path)
                predicted_class, confidence = run_inference(model, current_pil_img, class_names)
            params['clicked_open'] = False

        # 2. æª¢æŸ¥å‰ªè²¼ç°¿
        try:
            cb_img = ImageGrab.grabclipboard()
            if isinstance(cb_img, Image.Image):
                # ç°¡å–®çš„æ¯”å°æ–¹å¼ï¼šåˆ¤æ–·æ˜¯å¦ç‚ºæ–°åœ–
                if last_clipboard_img is None or cb_img.size != last_clipboard_img.size:
                    print("ğŸ“‹ åµæ¸¬åˆ°å‰ªè²¼ç°¿æ–°åœ–ç‰‡ï¼")
                    current_pil_img = cb_img
                    last_clipboard_img = cb_img
                    predicted_class, confidence = run_inference(model, current_pil_img, class_names)
        except:
            pass

        # 3. é¡¯ç¤ºç•«é¢
        if current_pil_img:
            # å°‡ PIL è½‰å› OpenCV æ ¼å¼é€²è¡Œé¡¯ç¤º
            display_img = np.array(current_pil_img.convert('RGB'))
            display_img = cv2.cvtColor(display_img, cv2.COLOR_RGB2BGR)
            # å›ºå®šé¡¯ç¤ºå¤§å°
            display_img = cv2.resize(display_img, (600, 500))
        else:
            display_img = np.zeros((500, 600, 3), dtype=np.uint8)

        draw_ui(display_img, predicted_class, confidence)
        cv2.imshow('CIFAR-10 TF Inference', display_img)

    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()