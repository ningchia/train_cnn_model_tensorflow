import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, optimizers
import numpy as np
import os
import json
import time

# --- 1. é…ç½®èˆ‡åƒæ•¸è¨­å®š ---
# èˆ‡ PyTorch ç‰ˆæœ¬ä¿æŒä¸€è‡´
MODEL_SAVE_PATH = "trained_model_tf"
CHECKPOINT_FILE = "latest_checkpoint_cifar10_mobilenet.keras"
CLASS_INDICES_FILE = "class_indices_cifar10.json"

NUM_CLASSES = 10
NUM_EPOCHS = 50 # åƒ…è¨“ç·´ 50 å€‹ Epochs
BATCH_SIZE = 32
TRANSFER_LEARNING_LR = 0.001
IMAGE_SIZE = (224, 224) 
START_MONITORING_EPOCH = 30  # å¾ç¬¬ 30 å€‹ Epoch é–‹å§‹ç›£æ§ EarlyStopping

# ImageNet æ¨™æº–åŒ–åƒæ•¸
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

# CIFAR-10 é¡åˆ¥åç¨±
CIFAR10_CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# --- 2. è¼”åŠ©å‡½å¼ï¼šæ•¸æ“šé è™•ç† ---
def preprocess_data(image, label):
    # 1.è½‰æ›ç‚º float32 ä¸¦æ­¸ä¸€åŒ–åˆ° [0, 1]
    #   Resize åˆ° MobileNetV2 æœŸæœ›çš„ 224x224
    image = tf.cast(image, tf.float32) / 255.0
    image = tf.image.resize(image, IMAGE_SIZE)

    # 2. å¹¾ä½•æ“´å¢ï¼ˆç¿»è½‰ä¸å½±éŸ¿æ•¸å€¼ç¯„åœï¼Œéš¨æ™‚å¯ä»¥åšï¼‰
    image = tf.image.random_flip_left_right(image)
    
    # 3. æ•¸å€¼æ“´å¢ï¼ˆé‡é»ï¼šåƒæ•¸å¿…é ˆå¾ˆå°ï¼Œå› ç‚ºç›®å‰æ˜¯ 0~1ï¼‰
    # é€™è£¡ max_delta=0.1 ä»£è¡¨äº®åº¦éš¨æ©Ÿå¢æ¸›æœ€å¤§ 10%
    image = tf.image.random_brightness(image, max_delta=0.1) 
    # éš¨æ©Ÿå°æ¯”åº¦ï¼Œåƒæ•¸æ˜¯å€ç‡ï¼Œé€šå¸¸ä¸å½±éŸ¿é‡ç´šï¼Œä½†ä»å»ºè­°æ”¾åœ¨æ¨™æº–åŒ–å‰
    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)

    # 4. é‡è¦æ­¥é©Ÿï¼šæˆªæ–·ï¼ˆClippingï¼‰
    # ç¢ºä¿äº®åº¦èª¿æ•´å¾Œï¼Œæ•¸å€¼ä¾ç„¶åš´æ ¼è½åœ¨ [0, 1] ä¹‹é–“
    image = tf.clip_by_value(image, 0.0, 1.0)

    # 5. æœ€å¾Œæ‰é€²è¡Œ ImageNet æ¨™æº–åŒ– (æ¸›å‡å€¼ã€é™¤æ–¹å·®)
    # ç¶“éé€™æ­¥å¾Œï¼Œæ•¸å€¼æœƒè®Šæˆæœ‰æ­£æœ‰è² ï¼ˆä¾‹å¦‚ -2.1 åˆ° 2.3ï¼‰ï¼Œé€™æ‰æ˜¯æ¨¡å‹æœ€å–œæ­¡çš„è¼¸å…¥
    # åŸ·è¡Œ ImageNet æ¨™æº–åŒ–
    image = (image - IMAGENET_MEAN) / IMAGENET_STD
    
    # æ¨™ç±¤è½‰ç‚º One-hot (å› æ¨¡å‹ä½¿ç”¨ categorical_crossentropy)
    label = tf.one_hot(label, NUM_CLASSES)
    return image, label

# --- 3. æ•¸æ“šåŠ è¼‰èˆ‡é¡åˆ¥å­—å…¸å„²å­˜ ---
def get_dataset():
    print("æ­£åœ¨è¼‰å…¥ CIFAR-10 æ•¸æ“šé›†...")
    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

    print(f"è¨“ç·´å½±åƒå½¢ç‹€: {x_train.shape}") # è¼¸å‡º: (50000, 32, 32, 3) -> (å¼µæ•¸, é«˜, å¯¬, é€šé“)
    print(f"è¨“ç·´æ¨™ç±¤å½¢ç‹€: {y_train.shape}") # è¼¸å‡º: (50000, 1)
    print(f"å½±åƒåƒç´ é¡å‹: {x_train.dtype}") # è¼¸å‡º: uint8 (0-255 çš„æ•´æ•¸)
    print(f"ç¬¬ä¸€ç­†æ¨™ç±¤å…§å®¹: {y_train[0]}") # è¼¸å‡º: [6]
    
    # æ‰å¹³åŒ–æ¨™ç±¤ (cifar10 è¼‰å…¥æ™‚æ˜¯ [[label], [label]])
    y_train = y_train.flatten()
    y_test = y_test.flatten()

    # å»ºç«‹èˆ‡å„²å­˜é¡åˆ¥å­—å…¸ï¼Œä¾›æ¨è«–è…³æœ¬è®€å–
    class_indices = {name: i for i, name in enumerate(CIFAR10_CLASSES)}
    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)
    with open(os.path.join(MODEL_SAVE_PATH, CLASS_INDICES_FILE), 'w') as f:
        json.dump(class_indices, f, indent=4)
    print(f"âœ… é¡åˆ¥ç´¢å¼•å·²å„²å­˜è‡³: {os.path.join(MODEL_SAVE_PATH, CLASS_INDICES_FILE)}")

    # å»ºç«‹ tf.data ç®¡é“ (é«˜æ•ˆä¸¦è¡Œè™•ç†)
    # .from_tensor_slices å¾è¨˜æ†¶é«”æˆ–ç¡¬ç¢Ÿè®€å–æ•¸æ“š
    # .map() è®“ CPU å¤šæ ¸å¿ƒä¸¦è¡ŒåŸ·è¡Œ tf.image çš„å‹•ä½œï¼ˆå¦‚éš¨æ©Ÿç¿»è½‰ã€æ¨™æº–åŒ–ï¼‰. tf.data.AUTOTUNE æœƒè‡ªå‹•åˆ†é…é©ç•¶çš„threadæ•¸ä¾†åš tf.image è™•ç†.
    # .prefetch() è®“ CPU åœ¨ GPU è¨“ç·´ç•¶å‰æ‰¹æ¬¡ï¼ˆBatchï¼‰æ™‚ï¼Œå°±é å…ˆæº–å‚™å¥½ä¸‹ä¸€å€‹æ‰¹æ¬¡.
    # .shuffle(5000) å…ˆå¾æ•¸æ“šåº«ä¸­å–å‡ºå‰ 5000 å¼µåœ–æ”¾é€²ä¸€å€‹ã€Œç·©è¡å€ï¼ˆBufferï¼‰ã€ã€‚
    #                å¾é€™ 5,000 å¼µåœ–ä¸­éš¨æ©ŸæŠ½å‡ºä¸€å€‹é€å»è¨“ç·´ã€‚å†å¾åŸå§‹æ•¸æ“šåº«å–ä¸‹ä¸€å¼µæ–°åœ–è£œé€²ä¾†ã€‚é‡è¤‡é€™å€‹å‹•ä½œã€‚
    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
    train_ds = train_ds.shuffle(5000).map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
    val_ds = val_ds.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

    return train_ds, val_ds

# --- 4. å»ºç«‹é·ç§»å­¸ç¿’æ¨¡å‹ ---
def create_transfer_model():
    # 1. è¼‰å…¥é è¨“ç·´ MobileNetV2ï¼Œä¸å«é ‚å±¤åˆ†é¡å™¨
    base_model = keras.applications.MobileNetV2(
        input_shape=IMAGE_SIZE + (3,),
        include_top=False,
        weights='imagenet'
    )
    
    # 2. å‡çµåŸºç¤å±¤ (åªè¨“ç·´åˆ†é¡é ­)
    base_model.trainable = False
    print("ğŸ’¡ æ¨¡å‹åŸºç¤ç‰¹å¾µæå–å±¤å·²å‡çµã€‚")

    # 3. å»ºç«‹è‡ªå®šç¾©åˆ†é¡é ­
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.2), # æ·»åŠ è¼•å¾® Dropout é˜²æ­¢éæ“¬åˆ
        layers.Dense(NUM_CLASSES, activation='softmax')     # è®“outputç›´æ¥æ˜¯æ©Ÿç‡åˆ†ä½ˆè€ŒéLogits.è®“å¾ŒçºŒmodel.predictä¸ç”¨åšsoftmax.
    ])
    
    return model

# --- 5. è¨“ç·´ä¸»ç¨‹å¼ ---
def main():
    train_ds, val_ds = get_dataset()
    model = create_transfer_model()

    # ç·¨è­¯æ¨¡å‹
    model.compile(
        optimizer=optimizers.Adam(learning_rate=TRANSFER_LEARNING_LR),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    model.summary()

    # è¨­å®šå›èª¿å‡½å¼ (å„²å­˜æœ€ä½³æ¨¡å‹èˆ‡ EarlyStopping)
    checkpoint_path = os.path.join(MODEL_SAVE_PATH, CHECKPOINT_FILE)
    callbacks = [
        keras.callbacks.ModelCheckpoint(
            filepath=checkpoint_path,
            monitor='val_accuracy',
            mode='max',
            save_best_only=True,
            verbose=1
        ),
        keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=10, # CIFAR-10 æ”¶æ–‚è¼ƒå¿«ï¼Œè¨­å®šå®¹å¿åº¦ 10
            restore_best_weights=True,
            start_from_epoch=START_MONITORING_EPOCH, # <--- å¾ç¬¬ N å€‹ Epoch æ‰é–‹å§‹æª¢æŸ¥åœæ­¢æ¢ä»¶ (Keras 3.0/TF 2.16+æ‰æ”¯æ´)
            verbose=1
        )
    ]

    print(f"\n--- é–‹å§‹é·ç§»å­¸ç¿’ (ç¸½ç›®æ¨™ Epoch: {NUM_EPOCHS}) ---")
    
    start_time = time.time()
    history = model.fit(
        train_ds,
        epochs=NUM_EPOCHS,
        validation_data=val_ds,
        callbacks=callbacks
    )
    end_time = time.time()

    print("-" * 50)
    print(f"è¨“ç·´è€—æ™‚: {(end_time - start_time)/60:.2f} åˆ†é˜")
    print(f"æœ€é«˜é©—è­‰æº–ç¢ºåº¦: {max(history.history['val_accuracy']):.4f}")

if __name__ == '__main__':
    main()